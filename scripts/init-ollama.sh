#!/bin/bash

echo "üöÄ Inicializando Ollama con modelo liviano..."

# Esperar a que Ollama est√© disponible
echo "‚è≥ Esperando a que Ollama est√© disponible..."
while ! curl -f http://ollama:11434/api/tags >/dev/null 2>&1; do
    echo "Esperando Ollama..."
    sleep 5
done

echo "‚úÖ Ollama est√° disponible"

# Verificar si el modelo ya est√° descargado
MODEL_NAME="qwen2.5:0.5b"
echo "üîç Verificando si el modelo $MODEL_NAME ya est√° descargado..."

if curl -s http://ollama:11434/api/tags | grep -q "$MODEL_NAME"; then
    echo "‚úÖ El modelo $MODEL_NAME ya est√° disponible"
else
    echo "üì• Descargando modelo $MODEL_NAME (m√°s liviano disponible)..."
    echo "‚ö†Ô∏è  Este proceso puede tardar varios minutos la primera vez..."
    
    # Descargar el modelo
    curl -X POST http://ollama:11434/api/pull \
        -H "Content-Type: application/json" \
        -d "{\"name\": \"$MODEL_NAME\"}" \
        --no-buffer
    
    echo ""
    echo "‚úÖ Modelo $MODEL_NAME descargado exitosamente"
fi

echo "üéâ Inicializaci√≥n de Ollama completada"
echo "üí° El modelo estar√° disponible en: http://localhost:11434"
echo "üìã Puedes probar el chat IA en: http://localhost:3000/api/chats/ia"
